{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "For RNN\n"
      ],
      "metadata": {
        "id": "PRoCEBMUFBbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model\n"
      ],
      "metadata": {
        "id": "BfxAIbmkFUe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the RNN model\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "# Generate sample data where output is perfectly predictable from the input\n",
        "input_size = 5\n",
        "hidden_size = 10\n",
        "output_size = 1\n",
        "num_samples = 100\n",
        "sequence_length = 3\n",
        "\n",
        "input_data = torch.randint(0, 2, (num_samples, sequence_length, input_size)).float()\n",
        "target_data = torch.sum(input_data, dim=(1,2)) %2\n",
        "target_data = target_data.unsqueeze(1)\n",
        "\n",
        "# Initialize the model, loss, and optimizer\n",
        "model = RNN(input_size, hidden_size, output_size)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop (increased epochs for better convergence)\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(input_data)\n",
        "    loss = criterion(outputs, target_data)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    outputs = model(input_data)\n",
        "    predicted = (outputs > 0.5).float()\n",
        "    accuracy = accuracy_score(target_data, predicted)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT7mH9axCo11",
        "outputId": "9b07ad71-3c14-4f60-95bb-1b3865dd848e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/500], Loss: 0.2768\n",
            "Epoch [200/500], Loss: 0.0211\n",
            "Epoch [300/500], Loss: 0.0072\n",
            "Epoch [400/500], Loss: 0.0041\n",
            "Epoch [500/500], Loss: 0.0028\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation matrices"
      ],
      "metadata": {
        "id": "YHxdqQHMFf7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    outputs = model(input_data)\n",
        "    predicted = (outputs > 0.5).float() # Convert probabilities to class labels (0 or 1)\n",
        "    actual = target_data\n",
        "\n",
        "    # Calculate classification metrics\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    print(classification_report(actual, predicted))\n",
        "    print(confusion_matrix(actual, predicted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LWQjQmREbUD",
        "outputId": "4148a630-fc88-4f28-bb16-b52b7f89ab20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00        59\n",
            "         1.0       1.00      1.00      1.00        41\n",
            "\n",
            "    accuracy                           1.00       100\n",
            "   macro avg       1.00      1.00      1.00       100\n",
            "weighted avg       1.00      1.00      1.00       100\n",
            "\n",
            "[[59  0]\n",
            " [ 0 41]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " For LSTM\n"
      ],
      "metadata": {
        "id": "uOMzDtreFMki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "M8wnclf3Fkd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sample data where output is perfectly predictable from the input\n",
        "input_size = 5\n",
        "hidden_size = 10\n",
        "output_size = 1\n",
        "num_samples = 100\n",
        "sequence_length = 3\n",
        "\n",
        "input_data = torch.randint(0, 2, (num_samples, sequence_length, input_size)).float()\n",
        "target_data = torch.sum(input_data, dim=(1,2)) % 2\n",
        "target_data = target_data.unsqueeze(1)\n",
        "\n",
        "# Define the LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "# Initialize the model, loss, and optimizer\n",
        "model = LSTM(input_size, hidden_size, output_size)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(input_data)\n",
        "    loss = criterion(outputs, target_data)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    outputs = model(input_data)\n",
        "    predicted = (outputs > 0.5).float()\n",
        "    accuracy = accuracy_score(target_data, predicted)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUSv4ZN-FPzJ",
        "outputId": "caeaa811-e2ad-4075-ef7c-ead1619b8e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/500], Loss: 0.1665\n",
            "Epoch [200/500], Loss: 0.0066\n",
            "Epoch [300/500], Loss: 0.0024\n",
            "Epoch [400/500], Loss: 0.0013\n",
            "Epoch [500/500], Loss: 0.0009\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Matrices"
      ],
      "metadata": {
        "id": "SXc2EHZtHuUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation matrices for the LSTM model (assuming 'model', 'input_data', and 'target_data' are defined)\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    outputs = model(input_data)\n",
        "    predicted = (outputs > 0.5).float()\n",
        "    actual = target_data\n",
        "\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    print(classification_report(actual, predicted))\n",
        "    print(confusion_matrix(actual, predicted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrTs_VsnG59A",
        "outputId": "7ea0e7fd-19e5-4b2c-f740-5158b7807e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00        48\n",
            "         1.0       1.00      1.00      1.00        52\n",
            "\n",
            "    accuracy                           1.00       100\n",
            "   macro avg       1.00      1.00      1.00       100\n",
            "weighted avg       1.00      1.00      1.00       100\n",
            "\n",
            "[[48  0]\n",
            " [ 0 52]]\n"
          ]
        }
      ]
    }
  ]
}